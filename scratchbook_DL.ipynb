{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sleep\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjinja2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Environment, FileSystemLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from jinja2 import Environment, FileSystemLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping sheet attrubites\n",
    "\n",
    "MAPPING_SHEET_NAME = 'Маппинг'\n",
    "\n",
    "mapping_sheet_col_names_target = [\n",
    "    'target_schema',\n",
    "    'target_table', \n",
    "    'target_attribute', \n",
    "    'target_attribute_full_name', \n",
    "    'target_attribute_short_desc',\n",
    "    'target_attribute_full_desc', \n",
    "    'target_attribute_data_type', \n",
    "    'target_attribute_algorithm',\n",
    "    'target_sla',\n",
    "]\n",
    "\n",
    "mapping_sheet_col_names_stage = [\n",
    "    'stage_schema', \n",
    "    'stage_table', \n",
    "    'stage_attribute',\n",
    "    'stage_attribute_full_name', \n",
    "    'stage_attribute_short_desc',\n",
    "    'stage_attribute_full_desc', \n",
    "    'stage_attribute_data_type', \n",
    "    'stage_attribute_is_pk', \n",
    "    'stage_attribute_is_fk',\n",
    "    'stage_attribute_is_not_null', \n",
    "]\n",
    "\n",
    "mapping_sheet_col_names_load_info = [\n",
    "    'load_initiator',\n",
    "    'load_initiator_object',\n",
    "    'load_strategy', \n",
    "    'load_schedule',\n",
    "    'load_comments',\n",
    "]\n",
    "\n",
    "mapping_sheet_col_names_source = [\n",
    "    'source_schema', \n",
    "    'source_table', \n",
    "    'source_attribute',\n",
    "    'source_attribute_full_name', \n",
    "    'source_attribute_short_desc',\n",
    "    'source_attribute_full_desc', \n",
    "    'source_attribute_data_type', \n",
    "    'source_attribute_is_pk', \n",
    "    'source_attribute_is_fk',\n",
    "    'source_attribute_is_not_null', \n",
    "    'source_check', \n",
    "    'source_new_values_tracking',\n",
    "    'source_entity_attribute_link', \n",
    "    'source_status', \n",
    "    'source_version',\n",
    "]\n",
    "\n",
    "mapping_sheet_col_names_common = [\n",
    "    'common_implementation_status',\n",
    "]\n",
    "\n",
    "mapping_sheet_col_names = \\\n",
    "    mapping_sheet_col_names_target + \\\n",
    "    mapping_sheet_col_names_stage + \\\n",
    "    mapping_sheet_col_names_load_info + \\\n",
    "    mapping_sheet_col_names_source + \\\n",
    "    mapping_sheet_col_names_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target tables sheet attrubites\n",
    "\n",
    "TARGET_TABLES_SHEET_NAME = 'Наборы данных'\n",
    "\n",
    "target_tables_sheet_col_names = [\n",
    "    'target_schema',\n",
    "    'target_table',\n",
    "    'target_table_desc',\n",
    "    'target_table_comment',\n",
    "    'target_table_distribution_clause',\n",
    "    'target_version',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage tables sheet attrubites\n",
    "\n",
    "STAGE_TABLES_SHEET_NAME = 'Таблицы-приемники'\n",
    "\n",
    "stage_tables_sheet_col_names = [\n",
    "    'stage_system',\n",
    "    'stage_schema',\n",
    "    'stage_table',\n",
    "    'stage_table_desc',\n",
    "    'stage_table_comment',\n",
    "    'stage_load_initiator',\n",
    "    'stage_load_initiator_object',\n",
    "    'stage_load_strategy', \n",
    "    'stage_load_schedule',\n",
    "    'stage_table_distribution_clause',\n",
    "    'stage_load_comments',\n",
    "    'stage_version',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source tables sheet attrubites\n",
    "\n",
    "SOURCE_TABLES_SHEET_NAME = 'Таблицы-источники'\n",
    "\n",
    "source_tables_sheet_col_names = [\n",
    "    'source_system',\n",
    "    'source_schema',\n",
    "    'source_table',\n",
    "    'source_table_desc',\n",
    "    'source_table_comment',\n",
    "    'source_table_rows_cnt',\n",
    "    'source_table_size_mb',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Excel S2T file name\n",
    "\n",
    "s2t_excel_filename = 'S2T_Data_Lake v8.6.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viktor.borodaenko\\AppData\\Local\\Temp\\ipykernel_16904\\2714804236.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).replace(r'\\s*(.*)\\s*', r'\\1', regex=True).fillna('')\n"
     ]
    }
   ],
   "source": [
    "# Parse Excel mappings  sheet\n",
    "\n",
    "s2t_dl_mapping_df = pd.read_excel(\n",
    "    f\"./S2T/{s2t_excel_filename}\", \n",
    "    engine = \"openpyxl\", \n",
    "    sheet_name = MAPPING_SHEET_NAME,\n",
    "    header = None, \n",
    "    skiprows = 2,\n",
    "    names = mapping_sheet_col_names,\n",
    "    index_col = None,\n",
    "    dtype = str,\n",
    ").replace(r'\\s*(.*)\\s*', r'\\1', regex=True).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viktor.borodaenko\\AppData\\Local\\Temp\\ipykernel_16904\\1906841768.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).replace(r'\\s*(.*)\\s*', r'\\1', regex=True).fillna('')\n"
     ]
    }
   ],
   "source": [
    "# Parse Excel target tables sheet\n",
    "\n",
    "s2t_dl_target_tables_df = pd.read_excel(\n",
    "    f\"./S2T/{s2t_excel_filename}\", \n",
    "    engine = \"openpyxl\", \n",
    "    sheet_name = TARGET_TABLES_SHEET_NAME,\n",
    "    header = None, \n",
    "    skiprows = 1,\n",
    "    names = target_tables_sheet_col_names,\n",
    "    index_col = None,\n",
    "    dtype = str,\n",
    ").replace(r'\\s*(.*)\\s*', r'\\1', regex=True).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viktor.borodaenko\\AppData\\Local\\Temp\\ipykernel_16904\\78345505.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).replace(r'\\s*(.*)\\s*', r'\\1', regex=True).fillna('')\n"
     ]
    }
   ],
   "source": [
    "# Parse Excel stage tables sheet\n",
    "\n",
    "s2t_dl_stage_tables_df = pd.read_excel(\n",
    "    f\"./S2T/{s2t_excel_filename}\", \n",
    "    engine = \"openpyxl\", \n",
    "    sheet_name = STAGE_TABLES_SHEET_NAME,\n",
    "    header = None, \n",
    "    skiprows = 1,\n",
    "    names = stage_tables_sheet_col_names,\n",
    "    index_col = None,\n",
    "    dtype = str,\n",
    ").replace(r'\\s*(.*)\\s*', r'\\1', regex=True).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viktor.borodaenko\\AppData\\Local\\Temp\\ipykernel_16904\\2737163241.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).replace(r'\\s*(.*)\\s*', r'\\1', regex=True).fillna('')\n"
     ]
    }
   ],
   "source": [
    "# Parse Excel source tables sheet\n",
    "\n",
    "s2t_dl_source_tables_df = pd.read_excel(\n",
    "    f\"./S2T/{s2t_excel_filename}\", \n",
    "    engine = \"openpyxl\", \n",
    "    sheet_name = SOURCE_TABLES_SHEET_NAME,\n",
    "    header = None, \n",
    "    skiprows = 1,\n",
    "    names = source_tables_sheet_col_names,\n",
    "    index_col = None,\n",
    "    dtype = str,\n",
    ").replace(r'\\s*(.*)\\s*', r'\\1', regex=True).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide mappings DataFrame by table types\n",
    "\n",
    "mapping_sheet_col_names_target += ['stage_attribute_is_pk', 'stage_attribute_is_not_null']\n",
    "\n",
    "s2t_dl_mapping_target_df = s2t_dl_mapping_df[mapping_sheet_col_names_target]\n",
    "\n",
    "s2t_dl_mapping_stage_df = s2t_dl_mapping_df[mapping_sheet_col_names_stage]\n",
    "\n",
    "s2t_dl_mapping_source_df = s2t_dl_mapping_df[mapping_sheet_col_names_source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target tables substitutes\n",
    "\n",
    "target_tables_substitutes = {}\n",
    "\n",
    "\n",
    "for _, row in s2t_dl_mapping_target_df.iterrows():\n",
    "    table = f'{row.target_schema}.{row.target_table}'\n",
    "    table_schema = row.target_schema\n",
    "    table_name = row.target_table\n",
    "\n",
    "    attribute = row.target_attribute\n",
    "    attribute_type = row.target_attribute_data_type\n",
    "    attribute_algorithm = row.target_attribute_algorithm\n",
    "    attribute_is_pk = row.stage_attribute_is_pk == 'PK'\n",
    "    attribute_is_not_null = row.stage_attribute_is_not_null == 'NOT NULL'\n",
    "\n",
    "    attribute_comment = ''\n",
    "    if row.target_attribute_short_desc:\n",
    "        attribute_comment += f'{row.target_attribute_short_desc}. '\n",
    "    if row.target_attribute_full_desc:\n",
    "        attribute_comment += f'{row.target_attribute_full_desc}. '\n",
    "    attribute_comment = attribute_comment.strip()\n",
    "\n",
    "    \n",
    "    if table not in target_tables_substitutes:\n",
    "        target_tables_substitutes[table] = {\n",
    "            'table_schema': table_schema,\n",
    "            'table_name': table_name,\n",
    "            'columns': {},\n",
    "        }\n",
    "    \n",
    "    target_tables_substitutes[table]['columns'][attribute] = {}\n",
    "\n",
    "    target_tables_substitutes[table]['columns'][attribute]['type'] = attribute_type\n",
    "    target_tables_substitutes[table]['columns'][attribute]['is_pk'] = attribute_is_pk\n",
    "    target_tables_substitutes[table]['columns'][attribute]['is_not_null'] = attribute_is_not_null\n",
    "    target_tables_substitutes[table]['columns'][attribute]['comment'] = attribute_comment\n",
    "    target_tables_substitutes[table]['columns'][attribute]['algorithm'] = attribute_algorithm\n",
    "\n",
    "\n",
    "for table, table_attrubutes in target_tables_substitutes.items():\n",
    "    target_tables_substitutes[table]['pk'] = []\n",
    "\n",
    "    for col_name, col_attribute in table_attrubutes['columns'].items():\n",
    "        if col_attribute['is_pk']:\n",
    "            target_tables_substitutes[table]['pk'].append(col_name)\n",
    "\n",
    "\n",
    "for _, row in s2t_dl_target_tables_df.iterrows():\n",
    "    table = f'{row.target_schema}.{row.target_table}'\n",
    "\n",
    "    table_distribution_clause = ''\n",
    "    if row.target_table_distribution_clause:\n",
    "        table_distribution_clause = row.target_table_distribution_clause\n",
    "    else:\n",
    "        table_distribution_clause = 'DISTRIBUTED RANDOMLY'\n",
    "\n",
    "    target_tables_substitutes[table]['distribution_clause'] = table_distribution_clause\n",
    "\n",
    "    table_comment = ''\n",
    "    if row.target_table_desc:\n",
    "        table_comment += f'Описание таблицы: {row.target_table_desc}. '\n",
    "    if row.target_table_comment:\n",
    "        table_comment += f'Комментарий: {row.target_attribute_full_desc}. '\n",
    "    if row.target_version:\n",
    "        table_comment += f'Версия: {row.target_version}. '\n",
    "    table_comment = table_comment.strip()\n",
    "\n",
    "    if table not in target_tables_substitutes:\n",
    "        print(f'Таблица {table} не найдена на листе маппингов!')\n",
    "        continue\n",
    "\n",
    "    target_tables_substitutes[table]['comment'] = table_comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage tables substitutes\n",
    "\n",
    "stage_tables_substitutes = {}\n",
    "\n",
    "\n",
    "for _, row in s2t_dl_mapping_stage_df.iterrows():\n",
    "    table = f'{row.stage_schema}.{row.stage_table}'\n",
    "    table_schema = row.stage_schema\n",
    "    table_name = row.stage_table\n",
    "    \n",
    "    attribute = row.stage_attribute\n",
    "    attribute_type = row.stage_attribute_data_type\n",
    "    attribute_is_pk = row.stage_attribute_is_pk.strip() == 'PK'\n",
    "    attribute_is_not_null = row.stage_attribute_is_not_null.strip() == 'NOT NULL'\n",
    "\n",
    "    attribute_comment = ''\n",
    "    if row.stage_attribute_short_desc:\n",
    "        attribute_comment += f'{row.stage_attribute_short_desc}. '\n",
    "    if row.stage_attribute_full_desc:\n",
    "        attribute_comment += f'{row.stage_attribute_full_desc}. '\n",
    "    attribute_comment = attribute_comment.strip()\n",
    "    \n",
    "    if table not in stage_tables_substitutes:\n",
    "        stage_tables_substitutes[table] = {\n",
    "            'table_schema': table_schema,\n",
    "            'table_name': table_name,\n",
    "            'columns': {},\n",
    "        }\n",
    "    \n",
    "    stage_tables_substitutes[table]['columns'][attribute] = {}\n",
    "\n",
    "    stage_tables_substitutes[table]['columns'][attribute]['type'] = attribute_type\n",
    "    stage_tables_substitutes[table]['columns'][attribute]['is_pk'] = attribute_is_pk\n",
    "    stage_tables_substitutes[table]['columns'][attribute]['is_not_null'] = attribute_is_not_null\n",
    "    stage_tables_substitutes[table]['columns'][attribute]['comment'] = attribute_comment\n",
    "\n",
    "\n",
    "\n",
    "for table, table_attrubutes in stage_tables_substitutes.items():\n",
    "    stage_tables_substitutes[table]['pk'] = []\n",
    "\n",
    "    for col_name, col_attribute in table_attrubutes['columns'].items():\n",
    "        if col_attribute['is_pk']:\n",
    "            stage_tables_substitutes[table]['pk'].append(col_name)\n",
    "\n",
    "\n",
    "for _, row in s2t_dl_stage_tables_df.iterrows():\n",
    "    table = f'{row.stage_schema}.{row.stage_table}'\n",
    "\n",
    "    table_distribution_clause = ''\n",
    "    if row.stage_table_distribution_clause:\n",
    "        table_distribution_clause = row.stage_table_distribution_clause\n",
    "    else:\n",
    "        table_distribution_clause = 'DISTRIBUTED RANDOMLY'\n",
    "\n",
    "    stage_tables_substitutes[table]['distribution_clause'] = table_distribution_clause\n",
    "\n",
    "    table_comment = ''\n",
    "    if row.stage_table_desc:\n",
    "        table_comment += f'Описание таблицы: {row.stage_table_desc}. '\n",
    "    if row.stage_table_comment:\n",
    "        table_comment += f'Комментарий: {row.stage_table_comment}. '\n",
    "    if row.stage_load_initiator:\n",
    "        table_comment += f'Инициализация обновления таблицы: {row.stage_load_initiator}. '\n",
    "    if row.stage_load_initiator_object:\n",
    "        table_comment += f'Объект инциализации: {row.stage_load_initiator_object}. '\n",
    "    if row.stage_load_strategy:\n",
    "        table_comment += f'Стратегия загрузки (Incr, Snap): {row.stage_load_strategy}. '\n",
    "    if row.stage_load_schedule:\n",
    "        table_comment += f'Регулярность загрузки : {row.stage_load_schedule}. '\n",
    "    if row.stage_load_comments:\n",
    "        table_comment += f'Комментарии к загрузке: {row.stage_load_comments}. '\n",
    "    if row.stage_version:\n",
    "        table_comment += f'Версия: {row.stage_version}. '\n",
    "    table_comment = table_comment.strip()\n",
    "\n",
    "    if table not in stage_tables_substitutes:\n",
    "        print(f'Таблица {table} не найдена на листе маппингов!')\n",
    "        continue\n",
    "\n",
    "    stage_tables_substitutes[table]['comment'] = table_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL tables substitutes for testing\n",
    "\n",
    "dl_tables_substitutes = {}\n",
    "\n",
    "\n",
    "for _, row in s2t_dl_mapping_source_df.iterrows():\n",
    "    table = f'{row.source_schema}.{row.source_table}'\n",
    "    table_schema = row.source_schema\n",
    "    table_name = row.source_table\n",
    "    \n",
    "    attribute = row.source_attribute\n",
    "    attribute_type = row.source_attribute_data_type\n",
    "    attribute_is_pk = row.source_attribute_is_pk.strip() == 'PK'\n",
    "    attribute_is_not_null = row.source_attribute_is_not_null.strip() == 'NOT NULL'\n",
    "\n",
    "    attribute_comment = ''\n",
    "    if row.source_attribute_short_desc:\n",
    "        attribute_comment += f'{row.source_attribute_short_desc}. '\n",
    "    if row.source_attribute_full_desc:\n",
    "        attribute_comment += f'{row.source_attribute_full_desc}. '\n",
    "    attribute_comment = attribute_comment.strip()\n",
    "    \n",
    "    if table not in dl_tables_substitutes:\n",
    "        dl_tables_substitutes[table] = {\n",
    "            'table_schema': table_schema,\n",
    "            'table_name': table_name,\n",
    "            'columns': {},\n",
    "        }\n",
    "    \n",
    "    dl_tables_substitutes[table]['columns'][attribute] = {}\n",
    "\n",
    "    dl_tables_substitutes[table]['columns'][attribute]['type'] = attribute_type\n",
    "    dl_tables_substitutes[table]['columns'][attribute]['is_pk'] = attribute_is_pk\n",
    "    dl_tables_substitutes[table]['columns'][attribute]['is_not_null'] = attribute_is_not_null\n",
    "    dl_tables_substitutes[table]['columns'][attribute]['comment'] = attribute_comment\n",
    "\n",
    "\n",
    "\n",
    "for table, table_attrubutes in dl_tables_substitutes.items():\n",
    "    dl_tables_substitutes[table]['pk'] = []\n",
    "\n",
    "    for col_name, col_attribute in table_attrubutes['columns'].items():\n",
    "        if col_attribute['is_pk']:\n",
    "            dl_tables_substitutes[table]['pk'].append(col_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jinja templates setup\n",
    "\n",
    "render_environment = Environment(loader=FileSystemLoader('./templates/'))\n",
    "\n",
    "gl_ddl_template = render_environment.get_template('DDL/GL.jinja')\n",
    "\n",
    "stg_ddl_template = render_environment.get_template('DDL/STG.jinja')\n",
    "\n",
    "dl_test_ddl_template = render_environment.get_template('DDL/DL_test.jinja')\n",
    "\n",
    "\n",
    "\n",
    "# templates for git\n",
    "\n",
    "git_gl_current_state_template = render_environment.get_template('DDL/git_GL_current_state.jinja')\n",
    "\n",
    "git_gl_001_init_down_template = render_environment.get_template('DDL/git_GL_001_init_down.jinja')\n",
    "\n",
    "git_gl_001_init_up_template = render_environment.get_template('DDL/git_GL_001_init_up.jinja')\n",
    "\n",
    "git_stg_current_state_template = render_environment.get_template('DDL/git_STG_current_state.jinja')\n",
    "\n",
    "git_stg_001_init_down_template = render_environment.get_template('DDL/git_STG_001_init_down.jinja')\n",
    "\n",
    "git_stg_001_init_up_template = render_environment.get_template('DDL/git_STG_001_init_up.jinja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render GL DDL Jinja templates for GitLab\n",
    "\n",
    "git_gl_current_state_output_folder = './output/git/gl'\n",
    "\n",
    "shutil.rmtree(git_gl_current_state_output_folder)\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "# current_state.sql\n",
    "for table_name, table in target_tables_substitutes.items():\n",
    "    table_name = table_name.split('.')[1]\n",
    "    output_filename = f'{git_gl_current_state_output_folder}/{table_name}/current_state.sql'\n",
    "    output_content = git_gl_current_state_template.render(table)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    with open(output_filename, mode=\"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_content)\n",
    "\n",
    "# 001_init/down.sql\n",
    "for table_name, table in target_tables_substitutes.items():\n",
    "    table_name = table_name.split('.')[1]\n",
    "    output_filename = f'{git_gl_current_state_output_folder}/{table_name}/001_init/down.sql'\n",
    "    output_content = git_gl_001_init_down_template.render(table)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    with open(output_filename, mode=\"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_content)\n",
    "\n",
    "# 001_init/up.sql\n",
    "for table_name, table in target_tables_substitutes.items():\n",
    "    table_name = table_name.split('.')[1]\n",
    "    output_filename = f'{git_gl_current_state_output_folder}/{table_name}/001_init/up.sql'\n",
    "    output_content = git_gl_001_init_up_template.render(table)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    with open(output_filename, mode=\"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render STG DDL Jinja templates for GitLab\n",
    "\n",
    "git_stg_current_state_output_folder = './output/git/stg'\n",
    "\n",
    "shutil.rmtree(git_stg_current_state_output_folder)\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "# current_state.sql\n",
    "for table_name, table in stage_tables_substitutes.items():\n",
    "    table_name = table_name.split('.')[1]\n",
    "    output_filename = f'{git_stg_current_state_output_folder}/{table_name}/current_state.sql'\n",
    "    output_content = git_stg_current_state_template.render(table)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    with open(output_filename, mode=\"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_content)\n",
    "\n",
    "# 001_init/down.sql\n",
    "for table_name, table in stage_tables_substitutes.items():\n",
    "    table_name = table_name.split('.')[1]\n",
    "    output_filename = f'{git_stg_current_state_output_folder}/{table_name}/001_init/down.sql'\n",
    "    output_content = git_stg_001_init_down_template.render(table)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    with open(output_filename, mode=\"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_content)\n",
    "\n",
    "# 001_init/up.sql\n",
    "for table_name, table in stage_tables_substitutes.items():\n",
    "    table_name = table_name.split('.')[1]\n",
    "    output_filename = f'{git_stg_current_state_output_folder}/{table_name}/001_init/up.sql'\n",
    "    output_content = git_stg_001_init_up_template.render(table)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    with open(output_filename, mode=\"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render DL test DDL Jinja templates\n",
    "\n",
    "dl_test_output_folder = './output/DDL/DL_test'\n",
    "\n",
    "files = glob.glob(f'{dl_test_output_folder}/*')\n",
    "for f in files:\n",
    "    if f != './output/DDL/DL_test\\_create_schemas.sql':\n",
    "        os.remove(f)\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "for table_name, table in dl_tables_substitutes.items():\n",
    "    output_filename = f'{table_name}.sql'\n",
    "    output_content = dl_test_ddl_template.render(table)\n",
    "\n",
    "    with open(f'{dl_test_output_folder}/{output_filename}', mode=\"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render GL DDL Jinja templates\n",
    "\n",
    "gl_output_folder = './output/DDL/GL/DL'\n",
    "\n",
    "files = glob.glob(f'{gl_output_folder}/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "for table_name, table in target_tables_substitutes.items():\n",
    "    output_filename = f'{table_name}.sql'\n",
    "    output_content = gl_ddl_template.render(table)\n",
    "\n",
    "    with open(f'{gl_output_folder}/{output_filename}', mode=\"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render STG DDL Jinja templates\n",
    "\n",
    "stg_output_folder = './output/DDL/STG/DL'\n",
    "\n",
    "files = glob.glob(f'{stg_output_folder}/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "for table_name, table in stage_tables_substitutes.items():\n",
    "    output_filename = f'{table_name}.sql'\n",
    "    output_content = stg_ddl_template.render(table)\n",
    "\n",
    "    with open(f'{stg_output_folder}/{output_filename}', mode=\"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all files\n",
    "\n",
    "with open('./output/DDL/DDL_DL_test.sql', mode=\"w\", encoding=\"utf-8\") as outfile:\n",
    "    \n",
    "    with open('./output/DDL/DL_test\\_create_schemas.sql', 'r', encoding=\"utf-8\") as readfile:\n",
    "        infile = readfile.read()\n",
    "        for line in infile:\n",
    "            outfile.write(line)\n",
    "        outfile.write(\"\\n\\n\")\n",
    "    dl_test_output_folder = './output/DDL/DL_test'\n",
    "    files = glob.glob(f'{dl_test_output_folder}/*')\n",
    "    for f in files:\n",
    "        if f != './output/DDL/DL_test\\_create_schemas.sql':\n",
    "            with open(f, 'r', encoding=\"utf-8\") as readfile:\n",
    "                infile = readfile.read()\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "                outfile.write(\"\\n\\n\")\n",
    "\n",
    "with open('./output/DDL/DDL_STG.sql', mode=\"w\", encoding=\"utf-8\") as outfile:\n",
    "    stg_output_folder = './output/DDL/STG/DL'\n",
    "    files = glob.glob(f'{stg_output_folder}/*')\n",
    "    for f in files:\n",
    "        with open(f, 'r', encoding=\"utf-8\") as readfile:\n",
    "            infile = readfile.read()\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "            outfile.write(\"\\n\\n\")\n",
    "    \n",
    "with open('./output/DDL/DDL_GL.sql', mode=\"w\", encoding=\"utf-8\") as outfile:\n",
    "    gl_output_folder = './output/DDL/GL/DL'\n",
    "    files = glob.glob(f'{gl_output_folder}/*')\n",
    "    for f in files:\n",
    "        with open(f, 'r', encoding=\"utf-8\") as readfile:\n",
    "            infile = readfile.read()\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "            outfile.write(\"\\n\\n\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
